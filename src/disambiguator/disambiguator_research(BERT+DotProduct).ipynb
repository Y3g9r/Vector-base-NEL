{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10309577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y3g9r\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ast\n",
    "import datetime as dt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760be49e",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb0542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisambiguationDataset(Dataset):\n",
    "    def __init__(self, samples,labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.len = len(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        items = {\"text_input_ids\": torch.tensor(self.samples[index][0]),\n",
    "                 \"text_input_mask\": torch.tensor(self.samples[index][1]),\n",
    "                 \"text_segment_ids\": torch.tensor(self.samples[index][2]),\n",
    "                 \"text_offset_mapping\": torch.tensor(self.samples[index][3]),\n",
    "                 \"text_pos\": torch.tensor(self.samples[index][4]),\n",
    "                 \"def_input_ids\": torch.tensor(self.samples[index][5]),\n",
    "                 \"def_input_mask\": torch.tensor(self.samples[index][6]),\n",
    "                 \"def_segment_ids\": torch.tensor(self.samples[index][7]),\n",
    "                 \"label\": torch.tensor(self.labels[index])}\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269a9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDistance():\n",
    "    def __init__(self, hidden_size=768, max_seq_len=388, device='cpu'):\n",
    "        self.device = device\n",
    "        self.bert = BertModel.from_pretrained('sberbank-ai/sbert_large_mt_nlu_ru', output_hidden_states=True,\n",
    "                                              return_dict=False)\n",
    "        for layer in self.bert.encoder.layer[:20]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                text_pos, def_input_ids, def_input_mask, def_segment_ids):\n",
    "\n",
    "        embd_batch = torch.tensor([[[], []]]).to(self.device)\n",
    "        first_pass = False\n",
    "        # получаем эмбединги ключевого слова из примера употребления\n",
    "        examples_token_key_word_position = self.token_detection(text_offset_mapping, text_pos[0])\n",
    "        example_token_vec = self.get_vector(text_input_ids, text_segment_ids,\n",
    "                                            text_input_mask)\n",
    "        example_embeddings = self.vector_recognition(example_token_vec, examples_token_key_word_position)\n",
    "\n",
    "        # получаем эмбединг определения\n",
    "        def_embedding = self.get_defenition_embedding(def_input_ids, def_segment_ids,\n",
    "                                                      def_input_mask).squeeze(0)\n",
    "        # объединяем два вектора в 1 и добавляем в общий массив (получаем тензор 2x768)\n",
    "        embd_sample = torch.stack((example_embeddings, def_embedding)).to(self.device)\n",
    "        if not first_pass:\n",
    "            embd_batch = torch.cat((embd_batch, embd_sample.unsqueeze(0)), -1)\n",
    "            first_pass = True\n",
    "        else:\n",
    "            embd_batch = torch.cat((embd_batch, embd_sample.unsqueeze(0)), 0)\n",
    "\n",
    "                \n",
    "        text_emb = embd_batch[:, 0, :]\n",
    "        def_emb = embd_batch[:, 1, :]\n",
    "\n",
    "\n",
    "        dist = torch.dot(text_emb.squeeze(0), def_emb.squeeze(0))\n",
    "\n",
    "        return dist\n",
    "\n",
    "    def get_defenition_embedding(self, def_input_ids, def_segment_ids, def_input_mask):\n",
    "        \"\"\"\n",
    "        Функция получения вектора дефенишина сущности\n",
    "        :param def_input_ids:\n",
    "        :param def_segment_ids:\n",
    "        :param def_input_mask:\n",
    "        :return: bert pooler output vector\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = self.bert(input_ids=def_input_ids.unsqueeze(0), token_type_ids=def_segment_ids.unsqueeze(0),\n",
    "                               attention_mask=def_input_mask.unsqueeze(0))\n",
    "        hidden_states = output[1]\n",
    "        return hidden_states\n",
    "\n",
    "    def token_detection(self, token_map, position):\n",
    "        \"\"\"\n",
    "        Функция определения ключевого слова\n",
    "        :param token_map: list of tuples of begin and end of every token\n",
    "        :param position:  list of type: [int,int]\n",
    "        :return: list of key word tokens position\n",
    "        \"\"\"\n",
    "        # из за того что в начале стоит CLS позиции начала и конца ключевого слова сдвигаются на 5\n",
    "        begin_postion = position[0]  # + 5\n",
    "        end_position = position[1]  # + 5\n",
    "\n",
    "        position_of_key_tokens = []\n",
    "        for token_tuple in range(1, len(token_map) - 1):\n",
    "            # Если ключевое слово представляется одним токеном\n",
    "            if token_map[token_tuple][0] == begin_postion and token_map[token_tuple][1] == end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "                break\n",
    "\n",
    "            # Если ключевое слово представляется несколькими токенами\n",
    "            if token_map[token_tuple][0] >= begin_postion and token_map[token_tuple][1] != end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "            if token_map[token_tuple][0] != begin_postion and token_map[token_tuple][1] == end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "                break\n",
    "\n",
    "        return position_of_key_tokens\n",
    "\n",
    "    def get_vector(self, input_ids_samp, token_type_ids_samp, attention_mask_samp):\n",
    "        \"\"\"\n",
    "        Функция получения вектора ключевого слова\n",
    "        :param input_ids_samp:\n",
    "        :param token_type_ids_samp:\n",
    "        :param attention_mask_samp:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids_samp.unsqueeze(0), token_type_ids=token_type_ids_samp.unsqueeze(0),\n",
    "                                attention_mask=attention_mask_samp.unsqueeze(0))\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "        # из [# layers, # batches, # tokens, # features]\n",
    "        # в [# tokens, # layers, # features]\n",
    "        token_dim = torch.stack(hidden_states, dim=0)\n",
    "        token_dim = torch.squeeze(token_dim, dim=1)\n",
    "        token_dim = token_dim.permute(1, 0, 2)\n",
    "        token_vecs_cat = []\n",
    "        for token in token_dim:\n",
    "            cat_vec = torch.sum(token[-4:], dim=0)\n",
    "            token_vecs_cat.append(cat_vec)\n",
    "        return token_vecs_cat\n",
    "\n",
    "\n",
    "    def vector_recognition(self, tokens_embeddings_ex, tokens_key_word_position_ex):\n",
    "        \"\"\"\n",
    "        Функция подготовки вектора в зависимости от количества токенов,которым представляется ключевое слово\n",
    "        :param tokens_embeddings_ex:\n",
    "        :param tokens_key_word_position_ex:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if len(tokens_key_word_position_ex) > 1:\n",
    "            embeddings_data = torch.tensor(\n",
    "                self.__get_avarage_embedding(tokens_embeddings_ex, tokens_key_word_position_ex))\n",
    "        else:\n",
    "            embeddings_data = torch.tensor(tokens_embeddings_ex[tokens_key_word_position_ex[0]])\n",
    "        return embeddings_data\n",
    "\n",
    "    def __get_avarage_embedding(self, embeddings_list, positions_list):\n",
    "        \"\"\"\n",
    "        Функция получения среднего вектора (применяется в случае если ключевое слово состоит из нескольких токенов)\n",
    "        :param embeddings_list:\n",
    "        :param positions_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        avg_tensor = torch.stack((embeddings_list[positions_list[0]],))\n",
    "        for i in range(1, len(positions_list)):\n",
    "            avg_tensor = torch.cat((avg_tensor, embeddings_list[positions_list[i]].unsqueeze(0)))\n",
    "\n",
    "        average_embedding = torch.mean(avg_tensor, 0)\n",
    "        return average_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dd98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(texts, definitions, position, labels, tokenizer, max_len):\n",
    "    tokenizer = tokenizer\n",
    "    feautures_X, feautures_Y = [], []\n",
    "\n",
    "    for i, (text, definition) in enumerate(zip(texts, definitions)):\n",
    "        text = tokenizer(text, return_offsets_mapping=True,max_length=max_len,truncation=True,padding='max_length')\n",
    "\n",
    "        text_input_ids = text[\"input_ids\"]\n",
    "        text_input_mask = text[\"attention_mask\"]\n",
    "        text_segment_ids = text[\"token_type_ids\"]\n",
    "        text_offset_mapping = text[\"offset_mapping\"]\n",
    "        text_pos = [position[i]]\n",
    "\n",
    "        definition = tokenizer(definition, return_offsets_mapping=True,max_length=max_len,padding='max_length',truncation=True)\n",
    "\n",
    "        def_input_ids = definition[\"input_ids\"]\n",
    "        def_input_mask = definition[\"attention_mask\"]\n",
    "        def_segment_ids = definition[\"token_type_ids\"]\n",
    "\n",
    "        feautures_X.append([text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                            text_pos, def_input_ids, def_input_mask, def_segment_ids])\n",
    "        feautures_Y.append(labels[i])\n",
    "\n",
    "    return feautures_X, feautures_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65dd3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y3g9r\\AppData\\Local\\Temp\\ipykernel_32472\\1125784648.py:118: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_data = torch.tensor(tokens_embeddings_ex[tokens_key_word_position_ex[0]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-====-\n",
      "tensor(-35.2622, device='cuda:0')\n",
      "tensor(-1.8885, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y3g9r\\AppData\\Local\\Temp\\ipykernel_32472\\1125784648.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_data = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-====-\n",
      "tensor(26.4184, device='cuda:0')\n",
      "tensor(33.7217, device='cuda:0')\n",
      "-====-\n",
      "tensor(9.1712, device='cuda:0')\n",
      "tensor(7.5576, device='cuda:0')\n",
      "-====-\n",
      "tensor(-26.4589, device='cuda:0')\n",
      "tensor(-9.2045, device='cuda:0')\n",
      "-====-\n",
      "tensor(17.4246, device='cuda:0')\n",
      "tensor(-16.5018, device='cuda:0')\n",
      "-====-\n",
      "tensor(-11.1964, device='cuda:0')\n",
      "tensor(-29.4029, device='cuda:0')\n",
      "-====-\n",
      "tensor(-10.5978, device='cuda:0')\n",
      "tensor(-14.9169, device='cuda:0')\n",
      "-====-\n",
      "tensor(-56.5371, device='cuda:0')\n",
      "tensor(28.7167, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "df = pd.read_csv('../../nn_data.csv')\n",
    "df.position = df.position.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "max_len_text = df.text.str.len().max()\n",
    "max_len_def = df.definition.str.len().max()\n",
    "\n",
    "max_len = max_len_def\n",
    "if max_len_text > max_len_def:\n",
    "    max_len = max_len_text\n",
    "\n",
    "data_X, data_Y = data_preparation(df.text,\n",
    "                                  df.definition,\n",
    "                                  df.position,\n",
    "                                  df.label,\n",
    "                                  BertTokenizerFast.from_pretrained('sberbank-ai/sbert_large_mt_nlu_ru',\n",
    "                                                                do_lower_case=True),\n",
    "                                  max_len)\n",
    "\n",
    "len_b = 16\n",
    "dataset = DisambiguationDataset(data_X[:len_b], data_Y[:len_b])\n",
    "\n",
    "model=BertDistance(max_seq_len=max_len, device='cuda:0')\n",
    "\n",
    "for i,sample in enumerate(dataset):\n",
    "    res = model.forward(sample['text_input_ids'], sample['text_input_mask'], sample['text_segment_ids'], \n",
    "                  sample['text_offset_mapping'], sample['text_pos'],sample['def_input_ids'],sample['def_input_mask'],\n",
    "                        sample['def_segment_ids'])\n",
    "    if i%2==0:\n",
    "        print(\"-====-\")\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16541e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
