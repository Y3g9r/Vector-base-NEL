{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10309577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y3g9r\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ast\n",
    "import datetime as dt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef96a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb0542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisambiguationDataset(Dataset):\n",
    "    def __init__(self, samples,labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.len = len(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        items = {\"text_input_ids\": torch.tensor(self.samples[index][0]),\n",
    "                 \"text_input_mask\": torch.tensor(self.samples[index][1]),\n",
    "                 \"text_segment_ids\": torch.tensor(self.samples[index][2]),\n",
    "                 \"text_offset_mapping\": torch.tensor(self.samples[index][3]),\n",
    "                 \"text_pos\": torch.tensor(self.samples[index][4]),\n",
    "                 \"def_input_ids\": torch.tensor(self.samples[index][5]),\n",
    "                 \"def_input_mask\": torch.tensor(self.samples[index][6]),\n",
    "                 \"def_segment_ids\": torch.tensor(self.samples[index][7]),\n",
    "                 \"label\": torch.tensor(self.labels[index])}\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269a9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerualNet(nn.Module):\n",
    "    def __init__(self, hidden_size=768, max_seq_len=388, device='cpu'):\n",
    "        self.device = device\n",
    "        super(NerualNet, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('sberbank-ai/sbert_large_mt_nlu_ru', output_hidden_states=True,\n",
    "                                              return_dict=False)\n",
    "        for layer in self.bert.encoder.layer[:20]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.text_pooling = nn.MaxPool1d(kernel_size=max_seq_len, stride=1)\n",
    "        self.def_pooling = nn.MaxPool1d(kernel_size=max_seq_len, stride=1)\n",
    "\n",
    "        self.cos = torch.nn.CosineSimilarity()\n",
    "\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                text_pos, def_input_ids, def_input_mask, def_segment_ids):\n",
    "\n",
    "        embd_batch = torch.tensor([[[], []]]).to(self.device)\n",
    "        first_pass = False\n",
    "        for i in range(len(text_input_ids)):\n",
    "            # получаем эмбединги ключевого слова из примера употребления\n",
    "            examples_token_key_word_position = self.token_detection(text_offset_mapping[i], text_pos[i][0])\n",
    "            example_token_vec = self.get_vector(text_input_ids[i], text_segment_ids[i], text_input_mask[i])\n",
    "            example_embeddings = self.vector_recognition(example_token_vec, examples_token_key_word_position)\n",
    "\n",
    "            # получаем эмбединг определения\n",
    "            def_embedding = self.get_defenition_embedding(def_input_ids[i], def_segment_ids[i],\n",
    "                                                          def_input_mask[i]).squeeze(0)\n",
    "            # объединяем два вектора в 1 и добавляем в общий массив (получаем тензор 2x768)\n",
    "            embd_sample = torch.stack((example_embeddings, def_embedding)).to(self.device)\n",
    "            if not first_pass:\n",
    "                embd_batch = torch.cat((embd_batch, embd_sample.unsqueeze(0)), -1)\n",
    "                first_pass = True\n",
    "            else:\n",
    "                embd_batch = torch.cat((embd_batch, embd_sample.unsqueeze(0)), 0)\n",
    "\n",
    "                \n",
    "        text_emb = embd_batch[:, 0, :]\n",
    "        def_emb = embd_batch[:, 1, :]\n",
    "\n",
    "        text_pool = self.text_pooling(text_emb.unsqueeze(0))\n",
    "        def_pool = self.def_pooling(def_emb.unsqueeze(0))\n",
    "\n",
    "        cos_comp = self.cos(text_pool.squeeze(0), def_pool.squeeze(0))\n",
    "\n",
    "        y = self.sigm(cos_comp)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def get_defenition_embedding(self, def_input_ids, def_segment_ids, def_input_mask):\n",
    "        \"\"\"\n",
    "        Функция получения вектора дефенишина сущности\n",
    "        :param def_input_ids:\n",
    "        :param def_segment_ids:\n",
    "        :param def_input_mask:\n",
    "        :return: bert pooler output vector\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = self.bert(input_ids=def_input_ids.unsqueeze(0), token_type_ids=def_segment_ids.unsqueeze(0),\n",
    "                               attention_mask=def_input_mask.unsqueeze(0))\n",
    "        hidden_states = output[1]\n",
    "        return hidden_states\n",
    "\n",
    "    def token_detection(self, token_map, position):\n",
    "        \"\"\"\n",
    "        Функция определения ключевого слова\n",
    "        :param token_map: list of tuples of begin and end of every token\n",
    "        :param position:  list of type: [int,int]\n",
    "        :return: list of key word tokens position\n",
    "        \"\"\"\n",
    "        # из за того что в начале стоит CLS позиции начала и конца ключевого слова сдвигаются на 5\n",
    "        begin_postion = position[0]  # + 5\n",
    "        end_position = position[1]  # + 5\n",
    "\n",
    "        position_of_key_tokens = []\n",
    "        for token_tuple in range(1, len(token_map) - 1):\n",
    "            # Если ключевое слово представляется одним токеном\n",
    "            if token_map[token_tuple][0] == begin_postion and token_map[token_tuple][1] == end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "                break\n",
    "\n",
    "            # Если ключевое слово представляется несколькими токенами\n",
    "            if token_map[token_tuple][0] >= begin_postion and token_map[token_tuple][1] != end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "            if token_map[token_tuple][0] != begin_postion and token_map[token_tuple][1] == end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "                break\n",
    "\n",
    "        return position_of_key_tokens\n",
    "\n",
    "    def get_vector(self, input_ids_samp, token_type_ids_samp, attention_mask_samp):\n",
    "        \"\"\"\n",
    "        Функция получения вектора ключевого слова\n",
    "        :param input_ids_samp:\n",
    "        :param token_type_ids_samp:\n",
    "        :param attention_mask_samp:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids_samp.unsqueeze(0), token_type_ids=token_type_ids_samp.unsqueeze(0),\n",
    "                                attention_mask=attention_mask_samp.unsqueeze(0))\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "        # из [# layers, # batches, # tokens, # features]\n",
    "        # в [# tokens, # layers, # features]\n",
    "        token_dim = torch.stack(hidden_states, dim=0)\n",
    "        token_dim = torch.squeeze(token_dim, dim=1)\n",
    "        token_dim = token_dim.permute(1, 0, 2)\n",
    "        token_vecs_cat = []\n",
    "        for token in token_dim:\n",
    "            cat_vec = torch.sum(token[-4:], dim=0)\n",
    "            token_vecs_cat.append(cat_vec)\n",
    "        return token_vecs_cat\n",
    "\n",
    "\n",
    "    def vector_recognition(self, tokens_embeddings_ex, tokens_key_word_position_ex):\n",
    "        \"\"\"\n",
    "        Функция подготовки вектора в зависимости от количества токенов,которым представляется ключевое слово\n",
    "        :param tokens_embeddings_ex:\n",
    "        :param tokens_key_word_position_ex:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if len(tokens_key_word_position_ex) > 1:\n",
    "            embeddings_data = torch.tensor(\n",
    "                self.__get_avarage_embedding(tokens_embeddings_ex, tokens_key_word_position_ex))\n",
    "        else:\n",
    "            embeddings_data = torch.tensor(tokens_embeddings_ex[tokens_key_word_position_ex[0]])\n",
    "        return embeddings_data\n",
    "\n",
    "    def __get_avarage_embedding(self, embeddings_list, positions_list):\n",
    "        \"\"\"\n",
    "        Функция получения среднего вектора (применяется в случае если ключевое слово состоит из нескольких токенов)\n",
    "        :param embeddings_list:\n",
    "        :param positions_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        avg_tensor = torch.stack((embeddings_list[positions_list[0]],))\n",
    "        for i in range(1, len(positions_list)):\n",
    "            avg_tensor = torch.cat((avg_tensor, embeddings_list[positions_list[i]].unsqueeze(0)))\n",
    "\n",
    "        average_embedding = torch.mean(avg_tensor, 0)\n",
    "        return average_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66ce6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, num_epochs=None, batch_size=None,\n",
    "                 max_batches_per_epoch=None, early_stopping=10,\n",
    "                 loss_fn=None, optimizer=None, model=None,\n",
    "                 scheduler=None, device='cpu'):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.max_batches_per_epoch = max_batches_per_epoch\n",
    "        self.early_stopping = early_stopping\n",
    "        self.loss_fn = loss_fn\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.start_model = model\n",
    "        self.best_model = model\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.valid_loss = []\n",
    "\n",
    "    def predict(self, input_ids, input_mask, segment_ids):\n",
    "        return self.best_model(input_ids, input_mask, segment_ids)\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        try:\n",
    "            torch.save(self.best_model, path)\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось сохранить модель. Ошибка {e}\")\n",
    "            exit(1)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        try:\n",
    "            self.best_model.load_state_dict(torch.load(path))\n",
    "        except Exception as e:\n",
    "            print(f\"Не удалось загрузить модель. Ошибка {e}\")\n",
    "            exit(1)\n",
    "\n",
    "        return True\n",
    "\n",
    "    def fit(self, train_dataset, valid_dataset):\n",
    "        device = torch.device(self.device)\n",
    "        NerualNet = self.start_model\n",
    "        NerualNet.to(device)\n",
    "\n",
    "        NerualNet.train()\n",
    "\n",
    "        self.optimizer = optim.Adam(NerualNet.parameters(), lr=0.0001)\n",
    "\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=self.batch_size,\n",
    "                                  shuffle=False, drop_last=True)\n",
    "        valid_loader = DataLoader(dataset=valid_dataset, batch_size=self.batch_size,\n",
    "                                  shuffle=False, drop_last=True)\n",
    "\n",
    "        best_val_loss = float('inf')  # Лучшее значение функции потерь на валидационной выборке\n",
    "\n",
    "        best_ep = 0  # Эпоха, на которой достигалось лучшее значение функции потерь на валидационной выборке\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            start = dt.datetime.now()\n",
    "            mean_loss = 0\n",
    "            batch_n = 0\n",
    "            for batch in train_loader:\n",
    "                y_truth = batch[\"label\"].float().to(device)\n",
    "                text_input_ids = batch[\"text_input_ids\"].to(device)\n",
    "                text_input_mask = batch[\"text_input_mask\"].to(device)\n",
    "                text_segment_ids = batch[\"text_segment_ids\"].to(device)\n",
    "                text_offset_mapping = batch[\"text_offset_mapping\"].to(device)\n",
    "                text_pos = batch[\"text_pos\"].to(device)\n",
    "                def_input_ids = batch[\"def_input_ids\"].to(device)\n",
    "                def_input_mask = batch[\"def_input_mask\"].to(device)\n",
    "                def_segment_ids = batch[\"def_segment_ids\"].to(device)\n",
    "                y_pred = NerualNet(text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                                   text_pos, def_input_ids, def_input_mask, def_segment_ids).float()\n",
    "  \n",
    "                loss = self.loss_fn(y_pred, y_truth)\n",
    "                loss.requires_grad = True\n",
    "        \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                del batch\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "                mean_loss += float(loss)\n",
    "                batch_n += 1\n",
    "\n",
    "            mean_loss /= batch_n\n",
    "            self.train_loss.append(mean_loss)\n",
    "            print(f'Эпоха: {epoch + 1}\\n Train loss: {mean_loss}\\n {dt.datetime.now() - start} сек.\\n')\n",
    "\n",
    "            NerualNet.eval()\n",
    "            mean_loss = 0\n",
    "            batch_n = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in valid_loader:\n",
    "                    if self.max_batches_per_epoch is not None:\n",
    "                        if batch_n >= self.max_batches_per_epoch:\n",
    "                            break\n",
    "\n",
    "                target = batch[\"label\"].float().to(device)\n",
    "                text_input_ids = batch[\"text_input_ids\"].to(device)\n",
    "                text_input_mask = batch[\"text_input_mask\"].to(device)\n",
    "                text_segment_ids = batch[\"text_segment_ids\"].to(device)\n",
    "                text_offset_mapping = batch[\"text_offset_mapping\"].to(device)\n",
    "                text_pos = batch[\"text_pos\"].to(device)\n",
    "                def_input_ids = batch[\"def_input_ids\"].to(device)\n",
    "                def_input_mask = batch[\"def_input_mask\"].to(device)\n",
    "                def_segment_ids = batch[\"def_segment_ids\"].to(device)\n",
    "\n",
    "                predicted_values = NerualNet(text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                                             text_pos, def_input_ids, def_input_mask, def_segment_ids).float()\n",
    "                \n",
    "                loss = self.loss_fn(predicted_values, target)\n",
    "\n",
    "                del batch\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "                mean_loss += float(loss)\n",
    "                batch_n += 1\n",
    "\n",
    "            mean_loss /= batch_n\n",
    "            self.valid_loss.append(mean_loss)\n",
    "            print(f'Loss_val: {mean_loss}')\n",
    "\n",
    "            if mean_loss < best_val_loss:\n",
    "                self.best_model = NerualNet\n",
    "                best_val_loss = mean_loss\n",
    "                best_ep = epoch\n",
    "            elif epoch - best_ep > self.early_stopping:\n",
    "                print(f'{self.early_stopping} без улучшений. Прекращаем обучение...')\n",
    "                break\n",
    "            if self.scheduler is not None:\n",
    "                scheduler.step()\n",
    "            print()\n",
    "\n",
    "        print(\"-=-=-=-=-=-=-=-=-=-= Evaluation of the best model =-=-=-=-=-=-=-=-=-=-\")\n",
    "        plt.plot(range(len(self.train_loss)), self.train_loss, color='green', label='train', linestyle='solid')\n",
    "        plt.plot(range(len(self.valid_loss)), self.valid_loss, color='red', label='val', linestyle='solid')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_test = [float(sample['label']) for sample in valid_dataset]\n",
    "            Y_pred = []\n",
    "            Y_pred = [self.best_model(sample['input_ids'].unsqueeze(0).to(device),\n",
    "                                      sample['input_mask'].unsqueeze(0).to(device),\n",
    "                                      sample['segment_ids'].unsqueeze(0).to(device)) for sample in valid_dataset]\n",
    "            Y_pred = [float(y > 0.5) for y in Y_pred]\n",
    "            print()\n",
    "\n",
    "            print(f\"report: \\n\", classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6dd98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(texts, definitions, position, labels, tokenizer, max_len):\n",
    "    tokenizer = tokenizer\n",
    "    feautures_X, feautures_Y = [], []\n",
    "\n",
    "    for i, (text, definition) in enumerate(zip(texts, definitions)):\n",
    "        text = tokenizer(text, return_offsets_mapping=True,max_length=max_len,truncation=True,padding='max_length')\n",
    "\n",
    "        text_input_ids = text[\"input_ids\"]\n",
    "        text_input_mask = text[\"attention_mask\"]\n",
    "        text_segment_ids = text[\"token_type_ids\"]\n",
    "        text_offset_mapping = text[\"offset_mapping\"]\n",
    "        text_pos = [position[i]]\n",
    "\n",
    "        definition = tokenizer(definition, return_offsets_mapping=True,max_length=max_len,padding='max_length',truncation=True)\n",
    "\n",
    "        def_input_ids = definition[\"input_ids\"]\n",
    "        def_input_mask = definition[\"attention_mask\"]\n",
    "        def_segment_ids = definition[\"token_type_ids\"]\n",
    "\n",
    "        feautures_X.append([text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                            text_pos, def_input_ids, def_input_mask, def_segment_ids])\n",
    "        feautures_Y.append(labels[i])\n",
    "\n",
    "    return feautures_X, feautures_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2efbe5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dd3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y3g9r\\AppData\\Local\\Temp\\ipykernel_20888\\43734324.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_data = torch.tensor(tokens_embeddings_ex[tokens_key_word_position_ex[0]])\n",
      "C:\\Users\\y3g9r\\AppData\\Local\\Temp\\ipykernel_20888\\43734324.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_data = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 1\n",
      " Train loss: 0.8018796145915985\n",
      " 0:04:58.288960 сек.\n",
      "\n",
      "Loss_val: 0.9310926795005798\n",
      "\n",
      "Эпоха: 2\n",
      " Train loss: 0.8023142826677573\n",
      " 0:04:45.217826 сек.\n",
      "\n",
      "Loss_val: 0.9310926795005798\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DisambiguationDataset(test_X, test_Y)\n\u001b[0;32m     24\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,\n\u001b[0;32m     25\u001b[0m                   batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     26\u001b[0m                   loss_fn\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss(),\n\u001b[0;32m     27\u001b[0m                   model\u001b[38;5;241m=\u001b[39mNerualNet(max_seq_len\u001b[38;5;241m=\u001b[39mmax_len, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     28\u001b[0m                   device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, train_dataset, valid_dataset)\u001b[0m\n\u001b[0;32m     71\u001b[0m def_input_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef_input_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     72\u001b[0m def_segment_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef_segment_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 73\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mNerualNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_input_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_segment_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_offset_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtext_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdef_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdef_input_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdef_segment_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     76\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(y_pred, y_truth)\n\u001b[0;32m     77\u001b[0m loss\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mNerualNet.forward\u001b[1;34m(self, text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping, text_pos, def_input_ids, def_input_mask, def_segment_ids)\u001b[0m\n\u001b[0;32m     22\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(text_input_ids)):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# получаем эмбединги ключевого слова из примера употребления\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     examples_token_key_word_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_offset_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     example_token_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(text_input_ids[i], text_segment_ids[i], text_input_mask[i])\n\u001b[0;32m     27\u001b[0m     example_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_recognition(example_token_vec, examples_token_key_word_position)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mNerualNet.token_detection\u001b[1;34m(self, token_map, position)\u001b[0m\n\u001b[0;32m     78\u001b[0m position_of_key_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token_tuple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(token_map) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Если ключевое слово представляется одним токеном\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtoken_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken_tuple\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbegin_postion\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m token_map[token_tuple][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m end_position:\n\u001b[0;32m     82\u001b[0m         position_of_key_tokens\u001b[38;5;241m.\u001b[39mappend(token_tuple)\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../nn_data.csv')\n",
    "df.position = df.position.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "max_len_text = df.text.str.len().max()\n",
    "max_len_def = df.definition.str.len().max()\n",
    "\n",
    "max_len = max_len_def\n",
    "if max_len_text > max_len_def:\n",
    "    max_len = max_len_text\n",
    "\n",
    "data_X, data_Y = data_preparation(df.text,\n",
    "                                  df.definition,\n",
    "                                  df.position,\n",
    "                                  df.label,\n",
    "                                  BertTokenizerFast.from_pretrained('sberbank-ai/sbert_large_mt_nlu_ru',\n",
    "                                                                do_lower_case=True),\n",
    "                                  max_len)\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(data_X, data_Y, test_size = 0.2, random_state=42)\n",
    "\n",
    "train_dataset = DisambiguationDataset(train_X, train_Y)\n",
    "test_dataset = DisambiguationDataset(test_X, test_Y)\n",
    "\n",
    "trainer = Trainer(num_epochs=40,\n",
    "                  batch_size=8,\n",
    "                  loss_fn=nn.BCELoss(),\n",
    "                  model=NerualNet(max_seq_len=max_len, device='cuda:0'),\n",
    "                  device='cuda:0')\n",
    "\n",
    "trainer.fit(train_dataset=train_dataset, valid_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15464ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
