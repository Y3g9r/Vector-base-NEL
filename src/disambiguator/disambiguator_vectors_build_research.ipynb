{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10309577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y3g9r\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import  Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ast\n",
    "import datetime as dt\n",
    "import gc\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760be49e",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb0542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisambiguationDataset(Dataset):\n",
    "    def __init__(self, samples,labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.len = len(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        items = {\"text_input_ids\": torch.tensor(self.samples[index][0]),\n",
    "                 \"text_input_mask\": torch.tensor(self.samples[index][1]),\n",
    "                 \"text_segment_ids\": torch.tensor(self.samples[index][2]),\n",
    "                 \"text_offset_mapping\": torch.tensor(self.samples[index][3]),\n",
    "                 \"text_pos\": torch.tensor(self.samples[index][4]),\n",
    "                 \"def_input_ids\": torch.tensor(self.samples[index][5]),\n",
    "                 \"def_input_mask\": torch.tensor(self.samples[index][6]),\n",
    "                 \"def_segment_ids\": torch.tensor(self.samples[index][7]),\n",
    "                 \"label\": torch.tensor(self.labels[index])}\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269a9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertVectors():\n",
    "    def __init__(self, device='cuda:0'):\n",
    "        self.device = device\n",
    "        self.bert = BertModel.from_pretrained('sberbank-ai/sbert_large_mt_nlu_ru', output_hidden_states=True,\n",
    "                                              return_dict=False).to(self.device)\n",
    "        \n",
    "        for layer in self.bert.encoder.layer[:20]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "\n",
    "    def forward(self, text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                text_pos, def_input_ids, def_input_mask, def_segment_ids):\n",
    "\n",
    "        embd_batch = torch.tensor([[[], []]]).to(self.device)\n",
    "        first_pass = False\n",
    "        for i in range(len(text_input_ids)):\n",
    "            # получаем эмбединги ключевого слова из примера употребления\n",
    "            examples_token_key_word_position = self.token_detection(text_offset_mapping[i], text_pos[i][0])\n",
    "            example_token_vec = self.get_vector(text_input_ids[i], text_segment_ids[i], text_input_mask[i])\n",
    "            example_embeddings = self.vector_recognition(example_token_vec, examples_token_key_word_position)\n",
    "\n",
    "            # получаем эмбединг определения\n",
    "            def_embedding = self.get_defenition_embedding(def_input_ids[i], def_segment_ids[i],\n",
    "                                                          def_input_mask[i]).squeeze(0)\n",
    "            # объединяем два вектора в 1 и добавляем в общий массив (получаем тензор 2x768)\n",
    "            embd_sample = torch.stack((example_embeddings, def_embedding)).to(self.device)\n",
    "            if not first_pass:\n",
    "                embd_batch = torch.cat((embd_batch, embd_sample.unsqueeze(0)), -1)\n",
    "                first_pass = True\n",
    "            else:\n",
    "                embd_batch = torch.cat((embd_batch, embd_sample.unsqueeze(0)), 0)\n",
    "\n",
    "                \n",
    "        text_emb = embd_batch[:, 0, :]\n",
    "        def_emb = embd_batch[:, 1, :]\n",
    "        \n",
    "        return text_emb, def_emb\n",
    "\n",
    "\n",
    "\n",
    "    def get_defenition_embedding(self, def_input_ids, def_segment_ids, def_input_mask):\n",
    "        \"\"\"\n",
    "        Функция получения вектора дефенишина сущности\n",
    "        :param def_input_ids:\n",
    "        :param def_segment_ids:\n",
    "        :param def_input_mask:\n",
    "        :return: bert pooler output vector\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = self.bert(input_ids=def_input_ids.unsqueeze(0), token_type_ids=def_segment_ids.unsqueeze(0),\n",
    "                               attention_mask=def_input_mask.unsqueeze(0))\n",
    "        hidden_states = output[1]\n",
    "        return hidden_states\n",
    "\n",
    "    def token_detection(self, token_map, position):\n",
    "        \"\"\"\n",
    "        Функция определения ключевого слова\n",
    "        :param token_map: list of tuples of begin and end of every token\n",
    "        :param position:  list of type: [int,int]\n",
    "        :return: list of key word tokens position\n",
    "        \"\"\"\n",
    "        # из за того что в начале стоит CLS позиции начала и конца ключевого слова сдвигаются на 5\n",
    "        begin_postion = position[0]  # + 5\n",
    "        end_position = position[1]  # + 5\n",
    "\n",
    "        position_of_key_tokens = []\n",
    "        for token_tuple in range(1, len(token_map) - 1):\n",
    "            # Если ключевое слово представляется одним токеном\n",
    "            if token_map[token_tuple][0] == begin_postion and token_map[token_tuple][1] == end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "                break\n",
    "\n",
    "            # Если ключевое слово представляется несколькими токенами\n",
    "            if token_map[token_tuple][0] >= begin_postion and token_map[token_tuple][1] != end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "            if token_map[token_tuple][0] != begin_postion and token_map[token_tuple][1] == end_position:\n",
    "                position_of_key_tokens.append(token_tuple)\n",
    "                break\n",
    "\n",
    "        return position_of_key_tokens\n",
    "\n",
    "    def get_vector(self, input_ids_samp, token_type_ids_samp, attention_mask_samp):\n",
    "        \"\"\"\n",
    "        Функция получения вектора ключевого слова\n",
    "        :param input_ids_samp:\n",
    "        :param token_type_ids_samp:\n",
    "        :param attention_mask_samp:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids_samp.unsqueeze(0), token_type_ids=token_type_ids_samp.unsqueeze(0),\n",
    "                                attention_mask=attention_mask_samp.unsqueeze(0))\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "        # из [# layers, # batches, # tokens, # features]\n",
    "        # в [# tokens, # layers, # features]\n",
    "        token_dim = torch.stack(hidden_states, dim=0)\n",
    "        token_dim = torch.squeeze(token_dim, dim=1)\n",
    "        token_dim = token_dim.permute(1, 0, 2)\n",
    "        token_vecs_cat = []\n",
    "        for token in token_dim:\n",
    "            cat_vec = torch.sum(token[-4:], dim=0)\n",
    "            token_vecs_cat.append(cat_vec)\n",
    "        return token_vecs_cat\n",
    "\n",
    "\n",
    "    def vector_recognition(self, tokens_embeddings_ex, tokens_key_word_position_ex):\n",
    "        \"\"\"\n",
    "        Функция подготовки вектора в зависимости от количества токенов,которым представляется ключевое слово\n",
    "        :param tokens_embeddings_ex:\n",
    "        :param tokens_key_word_position_ex:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if len(tokens_key_word_position_ex) > 1:\n",
    "            embeddings_data = torch.tensor(\n",
    "                self.__get_avarage_embedding(tokens_embeddings_ex, tokens_key_word_position_ex))\n",
    "        else:\n",
    "            embeddings_data = torch.tensor(tokens_embeddings_ex[tokens_key_word_position_ex[0]])\n",
    "        return embeddings_data\n",
    "\n",
    "    def __get_avarage_embedding(self, embeddings_list, positions_list):\n",
    "        \"\"\"\n",
    "        Функция получения среднего вектора (применяется в случае если ключевое слово состоит из нескольких токенов)\n",
    "        :param embeddings_list:\n",
    "        :param positions_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        avg_tensor = torch.stack((embeddings_list[positions_list[0]],))\n",
    "        for i in range(1, len(positions_list)):\n",
    "            avg_tensor = torch.cat((avg_tensor, embeddings_list[positions_list[i]].unsqueeze(0)))\n",
    "\n",
    "        average_embedding = torch.mean(avg_tensor, 0)\n",
    "        return average_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dd98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(texts, definitions, position, labels, tokenizer, max_len):\n",
    "    tokenizer = tokenizer\n",
    "    feautures_X, feautures_Y = [], []\n",
    "\n",
    "    for i, (text, definition) in enumerate(zip(texts, definitions)):\n",
    "        text = tokenizer(text, return_offsets_mapping=True,max_length=max_len,truncation=True,padding='max_length')\n",
    "\n",
    "        text_input_ids = text[\"input_ids\"]\n",
    "        text_input_mask = text[\"attention_mask\"]\n",
    "        text_segment_ids = text[\"token_type_ids\"]\n",
    "        text_offset_mapping = text[\"offset_mapping\"]\n",
    "        text_pos = [position[i]]\n",
    "\n",
    "        definition = tokenizer(definition, return_offsets_mapping=True,max_length=max_len,padding='max_length',truncation=True)\n",
    "\n",
    "        def_input_ids = definition[\"input_ids\"]\n",
    "        def_input_mask = definition[\"attention_mask\"]\n",
    "        def_segment_ids = definition[\"token_type_ids\"]\n",
    "\n",
    "        feautures_X.append([text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "                            text_pos, def_input_ids, def_input_mask, def_segment_ids])\n",
    "        feautures_Y.append(labels[i])\n",
    "\n",
    "    return feautures_X, feautures_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65dd3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y3g9r\\AppData\\Local\\Temp\\ipykernel_16936\\2307715024.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_data = torch.tensor(tokens_embeddings_ex[tokens_key_word_position_ex[0]])\n",
      "C:\\Users\\y3g9r\\AppData\\Local\\Temp\\ipykernel_16936\\2307715024.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_data = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x1         x2 label\n",
      "0  17.160700  51.473015   red\n",
      "1  17.160696  51.473042   red\n",
      "2 -35.446915   3.385340   red\n",
      "3 -35.446903   3.385334   red\n",
      "4 -13.192699 -34.345650   red\n",
      "5 -13.192699 -34.345650   red\n",
      "6  55.036259 -21.625818   red\n",
      "7  55.036259 -21.625818   red\n",
      "8 -23.557354   1.113110   red\n",
      "9 -23.557354   1.113110   red\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no property 'figsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(emb_2d)\n\u001b[0;32m     55\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m---> 56\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_subplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m ax1\u001b[38;5;241m.\u001b[39mscatter(x\u001b[38;5;241m=\u001b[39memb_2d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx1\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39memb_2d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx2\u001b[39m\u001b[38;5;124m'\u001b[39m], color\u001b[38;5;241m=\u001b[39memb_2d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m],width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m)\n\u001b[0;32m     58\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m         args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])))\n\u001b[0;32m    770\u001b[0m     projection_class, pkw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_projection_requirements(\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 772\u001b[0m     ax \u001b[38;5;241m=\u001b[39m subplot_class_factory(projection_class)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpkw)\n\u001b[0;32m    773\u001b[0m     key \u001b[38;5;241m=\u001b[39m (projection_class, pkw)\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_subplots.py:34\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    Keyword arguments are passed to the Axes (sub)class constructor.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# _axes_class is set in the subplot_class_factory\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axes_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fig, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# This will also update the axes position.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_subplotspec(SubplotSpec\u001b[38;5;241m.\u001b[39m_from_subplot_args(fig, args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    451\u001b[0m     warn_deprecated(\n\u001b[0;32m    452\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    455\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py:646\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[1;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m yscale:\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_yscale(yscale)\n\u001b[1;32m--> 646\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_map()\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    649\u001b[0m     axis\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39m_pickled_cids\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    650\u001b[0m         axis\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m    651\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unit_change_handler(name)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\artist.py:1064\u001b[0m, in \u001b[0;36mArtist.update\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1062\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(func):\n\u001b[1;32m-> 1064\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m                                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no property \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1066\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AxesSubplot' object has no property 'figsize'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../nn_data.csv')\n",
    "df.position = df.position.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "max_len_text = df.text.str.len().max()\n",
    "max_len_def = df.definition.str.len().max()\n",
    "\n",
    "max_len = max_len_def\n",
    "if max_len_text > max_len_def:\n",
    "    max_len = max_len_text\n",
    "\n",
    "data_X, data_Y = data_preparation(df.text,\n",
    "                                  df.definition,\n",
    "                                  df.position,\n",
    "                                  df.label,\n",
    "                                  BertTokenizerFast.from_pretrained('sberbank-ai/sbert_large_mt_nlu_ru',\n",
    "                                                                do_lower_case=True),\n",
    "                                  max_len)\n",
    "\n",
    "dataset = DisambiguationDataset(data_X[:10], data_Y[:10])\n",
    "loader = DataLoader(dataset=dataset, batch_size=10,shuffle=False, drop_last=True)\n",
    "bv = BertVectors(\"cuda:0\")\n",
    "\n",
    "vect_dict = {\"text\":[], \"def\":[], \"label\": []}\n",
    "\n",
    "\n",
    "device=\"cuda:0\"\n",
    "for i,batch in enumerate(loader):\n",
    "    target = batch[\"label\"].float().to(device)\n",
    "    text_input_ids = batch[\"text_input_ids\"].to(device)\n",
    "    text_input_mask = batch[\"text_input_mask\"].to(device)\n",
    "    text_segment_ids = batch[\"text_segment_ids\"].to(device)\n",
    "    text_offset_mapping = batch[\"text_offset_mapping\"].to(device)\n",
    "    text_pos = batch[\"text_pos\"].to(device)\n",
    "    def_input_ids = batch[\"def_input_ids\"].to(device)\n",
    "    def_input_mask = batch[\"def_input_mask\"].to(device)\n",
    "    def_segment_ids = batch[\"def_segment_ids\"].to(device)\n",
    "\n",
    "\n",
    "    x1,x2 = bv.forward(text_input_ids, text_input_mask, text_segment_ids, text_offset_mapping,\n",
    "               text_pos, def_input_ids, def_input_mask, def_segment_ids)\n",
    "    \n",
    "    vect_dict[\"text\"].append(x1.detach().cpu().numpy())\n",
    "    vect_dict[\"def\"].append(x2.detach().cpu().numpy())\n",
    "    vect_dict[\"label\"].append(target.detach().cpu().numpy())\n",
    "    \n",
    "    vect_dict[\"text\"] = vect_dict[\"text\"][0]\n",
    "    vect_dict[\"def\"] = vect_dict[\"def\"][0]\n",
    "    vect_dict[\"label\"] = vect_dict[\"label\"][0]\n",
    "\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    text_2d = pd.DataFrame(pca.fit_transform(vect_dict[\"text\"]), columns=['x1', 'x2'])\n",
    "    text_2d['label'] = 'green'\n",
    "    \n",
    "    text_2d = pd.DataFrame(pca.fit_transform(vect_dict[\"text\"]), columns=['x1', 'x2'])\n",
    "    text_2d['label'] = 'green'\n",
    "    \n",
    "    \n",
    "    print(emb_2d)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot()\n",
    "    ax1.scatter(x=text_2d['x1'], y=text_2d['x2'], color=text_2d['label'])\n",
    "    ax1.scatter(x=emb_2d['x1'], y=emb_2d['x2'], color=emb_2d['label'])\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16541e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
